#!/bin/bash
# Downloads posts from a user on Eka's Portal (g4)

help() {
	echo "Usage: $0 [mode] [user/posts]
Download posts from Eka's Portal (g4)

Arguments:
  -h    (H)elp
  -f    (F)ull artist
  -p    Individual (P)osts"
	exit 1
}

# Options via arguments
while getopts 'fph' options; do
	case $options in
        f) mode=full;;
		p) mode=post;;
		h) help;;
		*) help;;
	esac
done

# Display help if no mode is set
[ $# -eq 0 ] && help

# Optional cookie
cookie="/home/katt/Downloads/cookies-aryion-com.txt"

# Correct corrupted modified date and download
download() {
    # Get header
    head=$(wget --load-cookies="$cookie" --quiet --server-response --spider "https://aryion.com/g4/data.php?id=$1")

    # Extract filename
    filename=$(grep filename <<< "$head" | grep -oP '"\K[^"\047]+(?=["\047])'| tr -d '\015')

    # .. and datestamp
    lastmodified=$(grep last-modified <<< "$head" | sed 's/last-modified: //g' | tr -d : | sed 's/./&:/19;s/./&:/22' | tr -d '\015')

    wget --load-cookies "$cookie" --content-disposition --quiet --show-progress --no-clobber "https://aryion.com/g4/data.php?id=$1"
    touch -d "$lastmodified" "$filename"
}

# Check what mode has been selected
if [ "$mode" = "post" ]; then
    for postid in "${@:2}"; do
        download "$postid"
    done
    exit
elif [ "$mode" = "full" ]; then
    # Get amount of pages
    echo "Checking amount of pages..."
    pages="$(
        curl -s "https://aryion.com/g4/latest/$1" | \
        grep -Eo "Page 1 of [[:digit:]]*" | \
        head -n1 | \
        awk 'NF>1{print $NF}'
    )"

    echo "Found $pages pages, gathering"
    # Get all pages found
    curl -s "https://aryion.com/g4/latest/$1&p=[1-$pages]" | \
    wget --quiet -O-

    # Get only the submissions
    grep view/ | \

    # Get only what's inside of each href
    sed -n 's/.*href="\([^"]*\).*/\1/p' | \

    # Get rid of everything before last slash, leaving only IDs
    grep -o '[^/]*$' | \

    while read -r postid; do
        download "$postid"
    done
else
    help
    exit
fi
